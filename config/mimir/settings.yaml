# Mimir Configuration File
# Ispirato alla saggezza di Mímir, custode della conoscenza
# Based on Moshi architecture with custom integrations

# ========================================
# GENERAL SETTINGS
# ========================================
general:
  name: "Mimir"
  version: "0.1.0"
  language: "it-IT"
  debug: true
  log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  data_dir: "./data"
  
  # Moshi base settings (compatibilità)
  moshi_compatible: true
  use_mimi_codec: true  # Usa Mimi per audio streaming

# ========================================
# LLM CONFIGURATION (Ollama)
# ========================================
llm:
  provider: "ollama"
  base_url: "http://localhost:11434"
  model: "llama3.2:3b"
  
  # Parametri generazione (ottimizzati per Llama3.2)
  temperature: 0.75  # Creatività (0.0-1.0) - leggermente più alto per personalità
  top_p: 0.9
  top_k: 40
  repeat_penalty: 1.15  # Previene ripetizioni (importante per Llama)
  num_ctx: 8192  # Context window (Llama3.2 supporta fino a 128K)
  
  # Performance
  num_thread: 8  # Thread CPU (auto-detect se 0)
  num_gpu: 0  # Layer su GPU (0 = solo CPU)
  
  # Timeout & Retry
  timeout: 120  # secondi
  max_retries: 3
  
  # Streaming
  stream: true  # Risposta streaming

# ========================================
# ASR CONFIGURATION (Whisper)
# ========================================
asr:
  provider: "whisper"
  model: "medium"  # tiny, base, small, medium, large
  language: "it"
  
  # Performance
  device: "cpu"  # cpu o cuda
  compute_type: "int8"  # float16, int8 (più veloce)
  
  # Audio processing
  sample_rate: 16000
  chunk_duration: 30  # secondi
  
  # VAD (Voice Activity Detection)
  vad_enabled: true
  vad_threshold: 0.5
  silence_duration: 1.5  # secondi di silenzio per stop
  
  # Advanced
  beam_size: 5
  best_of: 5
  temperature: [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]

# ========================================
# TTS CONFIGURATION (XTTS v2)
# ========================================
tts:
  provider: "xtts"
  model: "tts_models/multilingual/multi-dataset/xtts_v2"
  language: "it"
  
  # Voice cloning
  speaker_wav: "./data/voice_models/mimir_voice.wav"
  use_custom_voice: true
  
  # Quality
  sample_rate: 22050
  
  # Speed & Performance
  speed: 1.0  # Velocità parlato (0.5-2.0)
  length_penalty: 1.0
  repetition_penalty: 2.0
  
  # Emotion (futuro)
  emotion: "calm"  # calm, wise, mysterious
  
  # Cache
  enable_cache: true
  cache_dir: "./data/voice_models/cache"

# ========================================
# AUDIO I/O
# ========================================
audio:
  input:
    device_index: null  # null = default, oppure numero device
    channels: 1  # Mono
    sample_rate: 16000
    chunk_size: 1024
    format: "int16"
  
  output:
    device_index: null
    channels: 1
    sample_rate: 22050
    buffer_size: 2048
    
  # Preprocessing
  noise_reduction: true
  auto_gain: true
  echo_cancellation: false

# ========================================
# MEMORY & CONTEXT
# ========================================
memory:
  enabled: true
  database: "./data/conversations/mimir.db"
  
  # Context management
  max_history: 10  # Messaggi da ricordare
  summarize_after: 20  # Riassumi dopo N messaggi
  
  # Persistence
  save_conversations: true
  conversation_retention_days: 365
  
  # Knowledge base (futuro)
  knowledge_enabled: false
  knowledge_dir: "./data/knowledge"

# ========================================
# PERSONALITY - L'essenza di Mimir
# ========================================
personality:
  name: "Mimir"
  archetype: "wise_sage"
  
  # Tono conversazionale
  tone: "calm_and_wise"  # calm_and_wise, mysterious, friendly
  formality: "respectful"  # casual, respectful, formal
  
  # Caratteristiche
  traits:
    - "knowledgeable"
    - "patient"
    - "thoughtful"
    - "ancient_wisdom"
    - "norse_mythology"
  
  # System prompt
  system_prompt_file: "./config/prompts.yaml"
  
  # Response style
  max_response_length: 500  # Parole
  prefer_concise: false  # Mimir può essere prolisso nella saggezza
  use_metaphors: true
  reference_mythology: true

# ========================================
# PERFORMANCE & OPTIMIZATION
# ========================================
performance:
  # Threading
  max_workers: 4
  
  # Caching
  enable_model_cache: true
  cache_dir: "./data/cache"
  
  # Monitoring
  log_performance: true
  profile_enabled: false
  
  # Limits
  max_audio_length: 300  # secondi
  max_response_time: 30  # secondi

# ========================================
# FUTURE EXTENSIONS
# ========================================
extensions:
  # LED Emotions (futuro)
  led:
    enabled: false
    gpio_pin: 18
    num_leds: 16
  
  # Vision (futuro)
  vision:
    enabled: false
    camera_index: 0
    model: "llava"
  
  # Web Interface (futuro)
  web:
    enabled: false
    host: "0.0.0.0"
    port: 8080
